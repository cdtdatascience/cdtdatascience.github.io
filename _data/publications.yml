- title: "Coping with Incomplete Data: Recent Advances"
  authors: Marco Console, Paolo Guagliardo, Leonid Libkin, Etienne Toussaint
  year: 2020 
  month:  6
  type: conference 
  published: Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems
  pages: 33-47
  abstract: >
    Handling incomplete data in a correct manner is a notoriously hard problem in databases. Theoretical approaches rely on the computationally hard notion of certain answers, while practical solutions rely on ad hoc query evaluation techniques based on three-valued logic. Can we find a middle ground, and produce correct answers efficiently?

- title: "Cryptocurrency Mining Games with Economic Discount and Decreasing Rewards"
  authors: Marcelo Arenas, Juan Reutter, Etienne Toussaint, MartÃ­n Ugarte, Francisco Vial, Domagoj Vrgoc
  year: 2020
  month: 12
  type: conference 
  published: 37th International Symposium on Theoretical Aspects of Computer Science (STACS 2020)
  publisher: 
  abstract: >
    In the consensus protocols used in most cryptocurrencies, participants called miners must find valid blocks of transactions and append them to a shared tree-like data structure. Ideally, the rules of the protocol should ensure that miners maximize their gains if they follow a default strategy, which consists on appending blocks only to the longest branch of the tree, called the blockchain. Our goal is to understand under which circumstances are miners encouraged to follow the default strategy. Unfortunately, most of the existing models work with simplified payoff functions, without considering the possibility that rewards decrease over time because of the game rules (like in Bitcoin), nor integrating the fact that a miner naturally prefers to be paid earlier than later (the economic concept of discount). In order to integrate these factors, we consider a more general model where issues such as economic discount and decreasing rewards can be set as parameters of an infinite stochastic game. In this model, we study the limit situation in which a miner does not receive a full reward for a block if it stops being in the blockchain. We show that if rewards are not decreasing, then miners do not have incentives to create new branches, no matter how high their computational power is. On the other hand, when working with decreasing rewards similar to those in Bitcoin, we show that miners have an incentive to create such branches. Nevertheless, this incentive only occurs when a miner controls a proportion of the computational power which is close to half of the computational power of the entire network.

- title: "Knowledge-Preserving Certain Answers for SQL-like Queries"
  authors: Etienne Toussaint, Paolo Guagliardo, Leonid Libkin
  year: 2020 
  month:  9
  type: conference 
  published: 17th International Conference on Principles of Knowledge Representation and Reasoning {KR-2020}
  pages: 758-767
  publisher: International Joint Conferences on Artificial Intelligence Organization
  abstract: >

- title: "Troubles with Nulls, Views from the Users"
  authors: Etienne Toussaint, Paolo Guagliardo, Leonid Libkin, Juan Sequeda
  year: 2022 
  month:  6
  type: journal 
  published: Proceedings of the VLDB Endowment (PVLDB)
  volume: 15
  publisher: Very Large Data Base Endowment Inc.
  abstract: >
    Incomplete data, in the form of null values, has been extensively studied since the inception of the relational model in the 1970s. Anecdotally, one hears that the way in which SQL, the standard language for relational databases, handles nulls creates a myriad of problems in everyday applications of database systems. To the best of our knowledge, however, the actual shortcomings of SQL in this respect, as perceived by database practitioners, have not been systematically documented, and it is not known if existing research results can readily be used to address the practical challenges. 

- title: "On the Tractability of Certain Answers for SQL Nulls in Relational Algebra with Inequalities."
  authors: Etienne Toussaint
  year: 2018
  month: 6
  type: conference 
  published: AMW
  abstract: >
    Missing values in theoretical models of incomplete database are often represented with marked nulls, while in SQL databases missing values are all denoted by the same syntactic NULL object. Even practical algorithm to approximate certain answers (answers which are true regardless of how incomplete information is interpreted) are often developed in the model with marked nulls. However computing certain answers for marked nulls is co-NP complete even for the most simple queries when inequalities are allowed. In this short paper we study the tractability of certain answers for SQL nulls in a fragment of relational algebra where selection with inequalities is permitted. We define the fragment and present an algorithm to compute certain answers. We also show that if we add even small features to the fragment, computing certain answers becomes intractable. This study emphasises the necessity of a specific certain answers approximation scheme for SQL nulls and offers ideas to design it.

- title: "Flexible Dataset Distillation: Learn Labels Instead of Images"
  authors: Ondrej Bohdal, Yongxin Yang, Timothy Hospedales
  year: 2020 
  month:  6
  type: preprint 
  published: arXiv preprint arXiv:2006.08572; NeurIPS MetaLearn 2020 Workshop
  abstract: >

- title: "Meta-Calibration: Meta-Learning of Model Calibration Using Differentiable Expected Calibration Error"
  authors: Ondrej Bohdal, Yongxin Yang, Timothy Hospedales
  year: 2021 
  month:  6
  type: workshop 
  published: arXiv preprint arXiv:2106.09613; ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning
  abstract: >

- title: "A Channel Coding Benchmark for Meta-Learning"
  authors: Rui Li, Ondrej Bohdal, Rajesh Mishra, Hyeji Kim, Da Li, Nicholas Lane, Timothy Hospedales
  year: 2021 
  month:  7
  type: conference 
  published: NeurIPS 2021 (Datasets and Benchmarks)
  abstract: >

- title: "EvoGrad: Efficient Gradient-Based Meta-Learning and Hyperparameter Optimization"
  authors: Ondrej Bohdal, Yongxin Yang, Timothy Hospedales
  year: 2021 
  month:  12
  type: conference 
  published: NeurIPS 2021
  abstract: >
    Gradient-based meta-learning and hyperparameter optimization have seen significant progress recently, enabling practical end-to-end training of neural networks together with many hyperparameters. Nevertheless, existing approaches are relatively expensive as they need to compute second-order derivatives and store a longer computational graph. This cost prevents scaling them to larger network architectures. We present EvoGrad, a new approach to meta-learning that draws upon evolutionary techniques to more efficiently compute hypergradients. EvoGrad estimates hypergradient with respect to hyperparameters without calculating second-order gradients, or storing a longer computational graph, leading to significant improvements in efficiency. We evaluate EvoGrad on three substantial recent meta-learning applications, namely cross-domain few-shot learning with feature-wise transformations, noisy label learning with Meta-Weight-Net and low-resource cross-lingual learning with meta representation transformation. The results show that EvoGrad significantly improves efficiency and enables scaling meta-learning to bigger architectures such as from ResNet10 to ResNet34.

- title: Feed-Forward Source-Free Domain Adaptation via Class Prototypes"
  authors: Ondrej Bohdal, Da Li, Timothy Hospedales
  year: 2022
  month: 10
  type: workshop
  published: ECCV 2022 OOD-CV Workshop

- title: "PASHA: Efficient HPO with Progressive Resource Allocation"
  authors: 
  year: 2022 
  month:  7
  type: workshop 
  published: arXiv preprint arXiv:2207.06940; AutoML Conference 2022 Workshop Track
  abstract: >

- title: "Feed-Forward Source-Free Latent Domain Adaptation via Cross-Attention"
  authors: Ondrej Bohdal, Da Li, Shell Xu Hu, Timothy Hospedales
  year: 2022
  month: 7
  type: workshop 
  published: arXiv preprint arXiv:2207.07624; ICML 2022 Workshop on Pre-training - Perspectives, Pitfalls, and Paths Forward
  abstract: >
  
- title: "EXOTica: An Extensible Optimization Toolset for Prototyping and Benchmarking Motion Planning and Control"
  authors: Vladimir Ivan, Yiming Yang, Wolfgang Merkt, Michael P Camilleri, Sethu Vijayakumar
  year: 2019
  month: 6
  type: conference 
  published: Robot Operating System (ROS)
  pages: 211-240
  publisher: Springer, Cham
  abstract: >

- title: "The technology behind a shared demand responsive transport system for a university campus"
  authors: Maria Attard, Michael PJ Camilleri, Adrian Muscat
  year: 2020 
  month:  9
  type: journal 
  published: Research in Transportation Business and Management
  volume: 36
  pages: 100463
  publisher: Elsevier
  abstract: >

- title: "An analytical method of assessment of RemoteFX as a cloud gaming platform"
  authors: Etienne Depasquale, Audrey Zammit, Michael Camilleri, Saviour Zammit, Adrian Muscat, Pierre Mallia, Stefan Scerri
  year: 2014 
  month:  4
  type: conference 
  published: MELECON 2014-2014 17th IEEE Mediterranean Electrotechnical Conference
  pages: 127-133
  publisher: IEEE
  abstract: >

- title: "Autonomous flight control for an RC helicopter"
  authors: Michael Camilleri, Kenneth Scerri, Saviour Zammit
  year: 2012 
  month:  3
  type: conference 
  published: 2012 16th IEEE Mediterranean Electrotechnical Conference
  pages: 391-394
  publisher: IEEE
  abstract: >

- title: "The extended dawid-skene model: Fusing information from multiple data schemas"
  authors: Michael PJ Camilleri, Christopher KI Williams
  year: 2019 
  month:  6
  type: journal 
  published: arXiv preprint arXiv:1906.01251
  abstract: >
    While label fusion from multiple noisy annotations is a well understood concept in data wrangling (tackled for example by the Dawid-Skene (DS) model), we consider the extended problem of carrying out learning when the labels themselves are not consistently annotated with the same schema. We show that even if annotators use disparate, albeit related, label-sets, we can still draw inferences for the underlying full label-set. We propose the Inter-Schema AdapteR (ISAR) to translate the fully-specified label-set to the one used by each annotator, enabling learning under such heterogeneous schemas, without the need to re-annotate the data. We apply our method to a mouse behavioural dataset, achieving significant gains (compared with DS) in out-of-sample log-likelihood (&#8722;3.40 to &#8722;2.39) and F1-score (0.785 to 0.864).

- title: "Modelling Annotator Variability across Feature Spaces in the Temporal Analysis of Behaviour"
  authors: Michael PJ Camilleri
  year: 2018 
  month:  11
  institution: MSc. dissertation, University of Edinburgh
  abstract: >
    Although behavioural phenotyping is an active area of research in the biological community, there is limited analysis in terms of temporal modelling of behavioural states. Moreover, while most of the data is obtained by human annotators indicating a behaviour from a predefined set of labels (which we call a schema), much of the research ignores the noise inherent in such data.

- title: "Developing the Technology for a Shared Demand Responsive Transport System at the University of Malta"
  authors: Maria Attard, Adrian Muscat, Michael Camilleri
  year: 2018 
  month:  1
  type: conference 
  published: Transportation Research Board 97th Annual Meeting
  abstract: >
    Shared Demand Responsive Transport services are flexible services increasingly regarded as an adequate and modern response to meet changing mobility demands. Research provides ample evidence from case studies, as well as the development of technological innovations to cater for and support such services. In Malta, Shared Demand Responsive Transport Services were already found to fill a gap as a mid-market alternative to the private car. The University of Malta is the highest teaching institution and home to a daytime population of 15,000 people, similar in size to any large town in the islands. The University is located at the centre of the island and adjacent to main roads. Complex travel patterns, aggregated in a small area, and restrictions on provision of car parking provided an opportunity for the team to develop the technology for a Shared Demand Responsive Transport System which is tailor-made to the mobility characteristics of the University. This paper provides a background to the case study and describes the development of the technology. Test results carried out at the University of Malta are presented in view of key service level parameters. The study found that the cost of the service is approximately double the cost of local buses, which cost difference is attributed to quality of service improvements. Overall the project demonstrates that ICT enabled demand responsive transport systems are feasible from both a technological and cost point of view. Such systems promise to deliver mobility solutions that compete very well with private car ownership and usage.

- title: Persistent Object Identification Leveraging Non-Visual Markers"
  authors: Michael PJ Camilleri, Li Zhang, Rasneer S Bains, Andrew Zisserman, Christopher KI Williams
  year: 2021 
  month:  12
  type: preprint 
  published: arXiv preprint arXiv:2112.06809

- title: "VJAGG--A Thick-Client Smart-Phone Journey Detection Algorithm"
  authors: Michael PJ Camilleri, Adrian Muscat, Victor Buttigieg, Maria Attard
  year: 2019 
  month:  8
  type: preprint 
  published: arXiv preprint arXiv:1908.10725
  abstract: >

- title: Automated personal trip identification app for mobility data collection in Malta"
  authors: Maria Attard, Michael Camilleri, Adrian Muscat, Victor Buttigieg
  year: 2017
  month: 6
  type: conference 
  published: NECTAR XIV International Conference on Transport in a Networked Society

- title: "Bert and pals: Projected attention layers for efficient adaptation in multi-task learning"
  authors: Asa Cooper Stickland, Iain Murray
  year: 2019 
  month:  5
  type: conference 
  published: International Conference on Machine Learning
  pages: 5986-5995
  publisher: PMLR
  abstract: >
    Multi-task learning shares information between related tasks, sometimes reducing the number of parameters required. State-of-the-art results across multiple natural language understanding tasks in the GLUE benchmark have previously used transfer from a single large task: unsupervised pre-training with BERT, where a separate BERT model was fine-tuned for each task. We explore multi-task approaches that share a\hbox {single} BERT model with a small number of additional task-specific parameters. Using new adaptation modules, PALs or 'projected attention layers';, we match the performance of separately fine-tuned models on the GLUE benchmark with approx 7 times fewer parameters, and obtain state-of-the-art results on the Recognizing Textual Entailment dataset.

- title: "Deep transformers with latent depth"
  authors: Xian Li, Asa Cooper Stickland, Yuqing Tang, Xiang Kong
  year: 2020
  month: 6
  type: journal 
  published: Advances in Neural Information Processing Systems
  volume: 33
  pages: 1736-1746
  abstract: >
    The Transformer model has achieved state-of-the-art performance in many sequence modeling tasks. However, how to leverage model capacity with large or variable depths is still an open challenge. We present a probabilistic framework to automatically learn which layer (s) to use by learning the posterior distributions of layer selection. As an extension of this framework, we propose a novel method to train one shared Transformer network for multilingual machine translation with different layer selection posteriors for each language pair. The proposed method alleviates the vanishing gradient issue and enables stable training of deep Transformers (eg 100 layers). We evaluate on WMT English-German machine translation and masked language modeling tasks, where our method outperforms existing approaches for training deeper Transformers. Experiments on multilingual machine translation demonstrate that this approach can effectively leverage increased model capacity and bring universal improvement for both many-to-one and one-to-many translation with diverse language pairs.

- title: "Recipes for adapting pre-trained monolingual and multilingual models to machine translation"
  authors: Asa Cooper Stickland, Xian Li, Marjan Ghazvininejad
  year: 2020 
  month:  4
  type: preprint 
  published: arXiv preprint arXiv:2004.14911
  abstract: >

- title: "Diverse ensembles improve calibration"
  authors: Asa Cooper Stickland, Iain Murray
  year: 2020 
  month:  7
  type: preprint 
  published: arXiv preprint arXiv:2007.04206
  abstract: >

- title: "Multilingual domain adaptation for nmt: Decoupling language and domain information with adapters"
  authors: Asa Cooper Stickland, Alexandre Berard, Vassilina Nikoulina
  year: 2021 
  month:  10
  type: preprint 
  published: arXiv preprint arXiv:2110.09574
  abstract: >

- title: "When does Parameter-Efficient Transfer Learning Work for Machine Translation?"
  authors: Ahmet Ustun, Asa Cooper Stickland
  year: 2022 
  month:  5
  type: preprint 
  published: arXiv preprint arXiv:2205.11277
  abstract: >

- title: "Robustification of Multilingual Language Models to Real-world Noise with Robust Contrastive Pretraining"
  authors: Asa Cooper Stickland, Sailik Sengupta, Jason Krone, Saab Mansour, He He
  year: 2022 
  month:  10
  type: preprint 
  published: arXiv preprint arXiv:2210.04782
  abstract: >

- title: "Regularising Fisher Information Improves Cross-lingual Generalisation"
  authors: Asa Cooper Stickland, Iain Murray
  year: 2021
  month: 11
  type: conference 
  published: Proceedings of the 1st Workshop on Multilingual Representation Learning
  pages: 238-241
  abstract: >
    Many recent works use 'consistency regularisation' to improve the generalisation of fine-tuned pre-trained models, both multilingual and English-only. These works encourage model outputs to be similar between a perturbed and normal version of the input, usually via penalising the Kullback-Leibler (KL) divergence between the probability distribution of the perturbed and normal model. We believe that consistency losses may be implicitly regularizing the loss landscape. In particular, we build on work hypothesising that implicitly or explicitly regularizing trace of the Fisher Information Matrix (FIM), amplifies the implicit bias of SGD to avoid memorization. Our initial results show both empirically and theoretically that consistency losses are related to the FIM, and show that the flat minima implied by a small trace of the FIM improves performance when fine-tuning a multilingual model on additional languages. We aim to confirm these initial results on more datasets, and use our insights to develop better multilingual fine-tuning techniques.

- title: "Neural Spline Flows"
  authors: Conor Durkan, Artur Bekasov, Iain Murray, George Papamakarios
  year: 2019
  month: 12
  type: conference 
  published: Advances in Neural Information Processing Systems
  pages: 7509-7520
  abstract: >
    A normalizing flow models a complex probability density as an invertible transformation of a simple base density. Flows based on either coupling or autoregressive transforms both offer exact density evaluation and sampling, but rely on the parameterization of an easily invertible elementwise transformation, whose choice determines the flexibility of these models. Building upon recent work, we propose a fully-differentiable module based on monotonic rational-quadratic splines, which enhances the flexibility of both coupling and autoregressive transforms while retaining analytic invertibility. We demonstrate that neural spline flows improve density estimation, variational inference, and generative modeling of images.

- title: "SBI - A toolkit for simulation-based inference"
  authors: Alvaro Tejero-Cantero, Jan Boelts, Michael Deistler, Jan-Matthis Lueckmann, Conor Durkan, Pedro J Goncalves, David S Greenberg, Jakob H Macke
  year: 2020 
  month:  7
  type: preprint 
  published: arXiv preprint arXiv:2007.09114
  abstract: >

- title: "Maximum Likelihood Training of Score-Based Diffusion Models"
  authors: Yang Song, Conor Durkan, Iain Murray, Stefano Ermon
  year: 2021
  month: 12
  type: conference 
  published: Advances in Neural Information Processing Systems
  abstract: >
    Score-based diffusion models synthesize samples by reversing a stochastic process that diffuses data to noise, and are trained by minimizing a weighted combination of score matching losses. The log-likelihood of score-based diffusion models can be tractably computed through a connection to continuous normalizing flows, but log-likelihood is not directly optimized by the weighted combination of score matching losses. We show that for a specific weighting scheme, the objective upper bounds the negative log-likelihood, thus enabling approximate maximum likelihood training of score-based diffusion models. We empirically observe that maximum likelihood training consistently improves the likelihood of score-based diffusion models across multiple datasets, stochastic processes, and model architectures. Our best models achieve negative log-likelihoods of 2.83 and 3.76 bits/dim on CIFAR-10 and ImageNet without any data augmentation, on a par with state-of-the-art autoregressive models on these tasks.

- title: "On Contrastive Learning for Likelihood-Free Inference"
  authors: Conor Durkan, Iain Murray, George Papamakarios
  year: 2020 
  month:  11
  type: conference 
  published: International Conference on Machine Learning
  pages: 2771-2781
  publisher: PMLR
  abstract: >
    Likelihood-free methods perform parameter inference in stochastic simulator models where evaluating the likelihood is intractable but sampling synthetic data is possible. One class of methods for this likelihood-free problem uses a classifier to distinguish between pairs of parameter-observation samples generated using the simulator and pairs sampled from some reference distribution, which implicitly learns a density ratio proportional to the likelihood. Another popular class of methods fits a conditional distribution to the parameter posterior directly, and a particular recent variant allows for the use of flexible neural density estimators for this task. In this work, we show that both of these approaches can be unified under a general contrastive learning scheme, and clarify how they should be run and compared.

- title: "Cubic-Spline Flows"
  authors: Conor Durkan, Artur Bekasov, Iain Murray, George Papamakarios
  year: 2019 
  month:  6
  type: preprint
  published: arXiv preprint arXiv:1906.02145
  abstract: >

- title: "Autoregressive Energy Machines"
  authors: Charlie Nash, Conor Durkan
  year: 2019 
  month:  5
  type: conference 
  published: International Conference on Machine Learning
  pages: 1735-1744
  abstract: >
    Neural density estimators are flexible families of parametric models which have seen widespread use in unsupervised machine learning in recent years. Maximum-likelihood training typically dictates that these models be constrained to specify an explicit density. However, this limitation can be overcome by instead using a neural network to specify an energy function, or unnormalized density, which can subsequently be normalized to obtain a valid distribution. The challenge with this approach lies in accurately estimating the normalizing constant of the high-dimensional energy function. We propose the Autoregressive Energy Machine, an energy-based model which simultaneously learns an unnormalized density and computes an importance-sampling estimate of the normalizing constant for each conditional in an autoregressive decomposition. The Autoregressive Energy Machine achieves state-of-the-art performance on a suite of density-estimation tasks.

- title: "Optical ultrafast random number generation at 1 Tb/s using a turbulent semiconductor ring cavity laser"
  authors: T Butler, C Durkan, D Goulding, S Slepneva, B Kelleher, SP Hegarty, G Huyet
  year: 2016 
  month:  1
  type: journal 
  published: Optics letters
  volume: 41
  issue: 2
  pages: 388-391
  publisher: Optical Society of America
  abstract: >

- title: "Sequential Neural Methods for Likelihood-Free Inference"
  authors: Conor Durkan, George Papamakarios, Iain Murray
  year: 2018 
  month:  11
  type: preprint 
  published: arXiv preprint arXiv:1811.08723
  abstract: >

- title: "How Well Do Self-Supervised Models Transfer?"
  authors: Linus Ericsson, Henry Gouk, Timothy M Hospedales
  year: 2021
  month: 6
  type: conference 
  published: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
  abstract: >
    Self-supervised visual representation learning has seen huge progress recently, but no large scale evaluation has compared the many models now available. We evaluate the transfer performance of 13 top self-supervised models on 40 downstream tasks, including many-shot and few-shot recognition, object detection, and dense prediction. We compare their performance to a supervised baseline and show that on most tasks the best self-supervised models outperform supervision, confirming the recently observed trend in the literature. We find ImageNet Top-1 accuracy to be highly correlated with transfer to many-shot recognition, but increasingly less so for few-shot, object detection and dense prediction. No single self-supervised method dominates overall, suggesting that universal pre-training is still unsolved. Our analysis of features suggests that top self-supervised learners fail to preserve colour information as well as supervised alternatives, but tend to induce better classifier calibration, and less attentive overfitting than supervised learners.

- title: "Self-Supervised Representation Learning: Introduction, advances, and challenges"
  authors: Linus Ericsson, Henry Gouk, Chen Change Loy, Timothy M Hospedales
  year: 2022 
  month:  IEEE Signal Processing Magazine
  volume: 39
  pages: 42-62
  type: journal
  publisher: IEEE Signal Processing Magazine
  abstract: >

- title: "Why do self-supervised models transfer? investigating the impact of invariance on downstream tasks"
  authors: Linus Ericsson, Henry Gouk, Timothy M Hospedales
  year: 2021 
  month:  11
  type: prerpint 
  published: arXiv preprint arXiv:2111.11398
  abstract: >

- title: "Region Proposal Network Pre-Training Helps Label-Efficient Object Detection"
  authors: Linus Ericsson, Nanqing Dong, Yongxin Yang, Ales Leonardis, Steven McDonagh
  year: 2022 
  month:  11
  type: preprint
  published: arXiv preprint arXiv:2211.09022
  abstract: >

- title: "BEETLE II: Deep natural language understanding and automatic feedback generation for intelligent tutoring in basic electricity and electronics"
  authors: Myroslava Dzikovska, Natalie Steinhauser, Elaine Farrow, Johanna Moore, Gwendolyn Campbell
  year: 2014
  month: 9
  type: journal 
  published: International Journal of Artificial Intelligence in Education
  volume: 24
  issue: 3
  pages: 284-332
  publisher: Springer New York
  abstract: >

- title: "Pilot randomised controlled trial of Help4Mood, an embodied virtual agent-based system to support treatment of depression"
  authors: Christopher Burton, Aurora Szentagotai Tatar, Brian McKinstry, Colin Matheson, Silviu Matu, Ramona Moldovan, Michele Macnab, Elaine Farrow, Daniel David, Claudia Pagliari, Antoni Serrano Blanco, Maria Wolters, Help4Mood Consortium
  year: 2016
  month: 9
  type: journal 
  published: Journal of telemedicine and telecare
  volume: 22
  issue: 6
  pages: 348-355
  publisher: SAGE Publications
  abstract: >
    Help4Mood is an interactive system with an embodied virtual agent (avatar) to assist in self-monitoring of patients receiving treatment for depression. Help4Mood supports self-report and biometric monitoring and includes elements of cognitive behavioural therapy. We aimed to evaluate system use and acceptability, to explore likely recruitment and retention rates in a clinical trial and to obtain an estimate of potential treatment response with a view to conducting a future randomised controlled trial (RCT). Methods: We conducted a pilot RCT of Help4Mood in three centres, in Romania, Spain and Scotland, UK. Patients with diagnosed depression (major depressive disorder) and current mild/moderate depressive symptoms were randomised to use the system for four weeks in addition to treatment as usual (TAU) or to TAU alone.

- title: "Beetle II: a system for tutoring and computational linguistics experimentation"
  authors: Myroslava O Dzikovska, Johanna D Moore, Natalie Steinhauser, Gwendolyn Campbell, Elaine Farrow, Charles B Callaway
  year: 2010
  month: 7
  type: conference 
  published: Proceedings of the ACL 2010 System Demonstrations
  pages: 13-18
  abstract: >
    We present BEETLE II, a tutorial dialogue system designed to accept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques.

- title: "Using natural language processing to analyze tutorial dialogue corpora across domains modalities"
  authors: Diane Litman, Johanna Moore, Myroslava O Dzikovska, Elaine Farrow
  year: 2009
  month: 6
  type: conference 
  published: Artificial Intelligence in Education
  pages: 149-156
  publisher: IOS Press
  abstract: >
    Our research goal is to investigate whether previous findings and methods in the area of tutorial dialogue can be generalized across dialogue corpora that differ in domain (mechanics versus electricity in physics), modality (spoken versus typed), and tutor type (computer versus human). We first present methods for unifying our prior coding and analysis methods. We then show that many of our prior findings regarding student dialogue behaviors and learning not only generalize across corpora, but that our methodology yields additional new findings. Finally, we show that natural language processing can be used to automate some of these analyses.

- title: "Analysing discussion forum data: a replication study avoiding data contamination"
  authors: Elaine Farrow, Johanna Moore, Dragan Gasevic
  year: 2019 
  month:  3
  type: conference 
  published: Proceedings of the 9th international conference on learning analytics &amp; knowledge
  pages: 170-179
  abstract: >
    The widespread use of online discussion forums in educational settings provides a rich source of data for researchers interested in how collaboration and interaction can foster effective learning. Such online behaviour can be understood through the Community of Inquiry framework, and the cognitive presence construct in particular can be used to characterise the depth of a student&#39;s critical engagement with course material. Automated methods have been developed to support this task, but many studies used small data sets, and there have been few replication studies.

- title: "Intelligent Tutoring with Natural Language Support in the BEETLE II System"
  authors: Myroslava O Dzikovska, Diana Bental, Johanna D Moore, Natalie B Steinhauser, Gwendolyn E Campbell, Elaine Farrow, Charles B Callaway
  year: 2010 
  month:  9
  type: conference 
  published: European Conference on Technology Enhanced Learning
  pages: 620-625
  publisher: Springer, Berlin, Heidelberg
  abstract: >
    We present Beetle II, a tutorial dialogue system designed to accept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutoring policies and demonstrated that Beetle II can be successfully used as a platform to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety of parameters that may affect learning in intelligent tutoring systems.

- title: "Dealing with interpretation errors in tutorial dialogue"
  authors: Myroslava O Dzikovska, Charles B Callaway, Elaine Farrow, Johanna D Moore, Natalie Steinhauser, Gwendolyn Campbell
  year: 2009
  month: 9
  type: conference 
  published: Proceedings of the SIGDIAL 2009 Conference
  pages: 38-45
  abstract: >
    We describe an approach to dealing with interpretation errors in a tutorial dialogue system. Allowing students to provide explanations and generate contentful talk can be helpful for learning, but the language that can be understood by a computer system is limited by the current technology. Techniques for dealing with understanding problems have been developed primarily for spoken dialogue systems in informationseeking domains, and are not always appropriate for tutorial dialogue. We present a classification of interpretation errors and our approach for dealing with them within an implemented tutorial dialogue system.

- title: "The Beetle and BeeDiff tutoring systems"
  authors: Charles Callaway, Myroslava Dzikovska, Elaine Farrow, Manuel Marques-Pita, Colin Matheson, Johanna D Moore
  year: 2007
  month: 5
  type: preprint
  abstract: >

- title: "Dialogue attributes that inform depth and quality of participation in course discussion forums"
  authors: Elaine Farrow, Johanna Moore, Dragan Gasevic
  year: 2020 
  month:  3
  type: conference 
  published: Proceedings of the tenth international conference on learning analytics and knowledge
  pages: 129-134
  abstract: >
    This paper describes work in progress to answer the question of how we can identify and model the depth and quality of student participation in class discussion forums using the content of the discussion forum messages. We look at two widely-studied frameworks for assessing critical discourse and cognitive engagement: the ICAP and Community of Inquiry (CoI) frameworks. Our goal is to discover where they agree and where they offer complementary perspectives on learning.

- title: "Diagnosing Natural Language Answers to Support Adaptive Tutoring."
  authors: Myroslava O Dzikovska, Gwendolyn E Campbell, Charles B Callaway, Natalie B Steinhauser, Elaine Farrow, Johanna D Moore, Leslie A Butler, Colin Matheson
  year: 2008
  month: 5
  type: conference 
  published: FLAIRS Conference
  pages: 403-408
  abstract: >
    Understanding answers to open-ended explanation questions is important in intelligent tutoring systems. Existing systems use natural language techniques in essay analysis, but revert to scripted interaction with short-answer questions during remediation, making adapting dialogue to individual students difficult. We describe a corpus study that shows that there is a relationship between the types of faulty answers and the remediation strategies that tutors use; that human tutors respond differently to different kinds of correct answers; and that re-stating correct answers is associated with improved learning. We describe a design for a diagnoser based on this study that supports remediation in open-ended questions and provides an analysis of natural language answers that enables adaptive generation of tutorial feedback for both correct and faulty answers.

- title: "'Why is the Doctor a Man'; Reactions of Older Adults to a Virtual Training Doctor"
  authors: Aurora Constantin, Catherine Lai, Elaine Farrow, Beatrice Alex, Ruth Pel-Littel, Henk Herman Nap, Johan Jeuring
  year: 2019 
  month:  5
  type: conference 
  published: Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems
  pages: 1-6
  abstract: >

- title: "Combining semantic interpretation and statistical classification for improved explanation processing in a tutorial dialogue system"
  authors: Myroslava O Dzikovska, Elaine Farrow, Johanna D Moore
  year: 2013 
  month:  7
  type: conference
  published: International Conference on Artificial Intelligence in Education
  pages: 279-288
  publisher: Springer, Berlin, Heidelberg
  abstract: >
    We present an approach for combining symbolic interpretation and statistical classification in the natural language processing (NLP) component of a tutorial dialogue system. Symbolic NLP approaches support dynamic generation of context-adaptive natural language feedback, but lack robustness. In contrast, statistical classification approaches are robust to ill-formed input but provide less detail for context-specific feedback generation. We describe a system design that combines symbolic interpretation with statistical classification to support context-adaptive, dynamically generated natural language feedback, and show that the combined system significantly improves interpretation quality while retaining the adaptivity benefits of a symbolic interpreter.

